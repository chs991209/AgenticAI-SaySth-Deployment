import React, { useState, useRef, useEffect } from 'react'
import { sendAudioToASR } from '../api'

interface MicrophoneButtonProps {
  onTranscript: (text: string) => void
  onVoiceCommand?: (text: string) => Promise<void>
  disabled?: boolean
}

const MicrophoneButton: React.FC<MicrophoneButtonProps> = ({
  onTranscript,
  onVoiceCommand,
  disabled = false,
}) => {
  const [isRecording, setIsRecording] = useState(false)
  const [isProcessing, setIsProcessing] = useState(false)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const audioChunksRef = useRef<Blob[]>([])

  useEffect(() => {
    return () => {
      // Cleanup: stop recording if component unmounts
      if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
        mediaRecorderRef.current.stop()
      }
    }
  }, [])

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      const mediaRecorder = new MediaRecorder(stream)
      mediaRecorderRef.current = mediaRecorder
      audioChunksRef.current = []

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data)
        }
      }

      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' })
        await processAudio(audioBlob)
        
        // Stop all tracks
        stream.getTracks().forEach((track) => track.stop())
      }

      mediaRecorder.start()
      setIsRecording(true)
    } catch (error) {
      console.error('Error starting recording:', error)
      alert('ÎßàÏù¥ÌÅ¨ Ï†ëÍ∑º Í∂åÌïúÏù¥ ÌïÑÏöîÌï©ÎãàÎã§.')
    }
  }

  const stopRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop()
      setIsRecording(false)
    }
  }

  const processAudio = async (audioBlob: Blob) => {
    setIsProcessing(true)
    try {
      const text = await sendAudioToASR(audioBlob)
      if (text) {
        onTranscript(text)
        // ÏùåÏÑ± Î™ÖÎ†πÏù∏ Í≤ΩÏö∞ ÏûêÎèôÏúºÎ°ú Ïã§Ìñâ
        if (onVoiceCommand) {
          await onVoiceCommand(text)
        }
      }
    } catch (error) {
      console.error('Error processing audio:', error)
      alert('ÏùåÏÑ± Ïù∏Ïãù Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§.')
    } finally {
      setIsProcessing(false)
    }
  }

  const handleClick = () => {
    if (disabled || isProcessing) return

    if (isRecording) {
      stopRecording()
    } else {
      startRecording()
    }
  }

  return (
    <button
      type="button"
      onClick={handleClick}
      disabled={disabled || isProcessing}
      className={`microphone-button ${isRecording ? 'recording' : ''} ${
        isProcessing ? 'processing' : ''
      }`}
      title={isRecording ? 'ÎÖπÏùå Ï§ëÏßÄ' : isProcessing ? 'Ï≤òÎ¶¨ Ï§ë...' : 'ÏùåÏÑ± ÏûÖÎ†• ÏãúÏûë'}
    >
      {isProcessing ? (
        <span className="spinner">‚è≥</span>
      ) : isRecording ? (
        <span className="recording-indicator">üî¥</span>
      ) : (
        <span>üé§</span>
      )}
    </button>
  )
}

export default MicrophoneButton

